{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Neural Network\n",
    "\n",
    "In this review session, we will go through how to code a neural network by hand using `numpy`. The material used here is based on Andrew Ng's Deep Learning course on coursera. We will then apply off-the-shelf feedforward neural nets for different types of tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will use the dataset from Angrist and Krueger (1991), and we will predict whether a person received more than 12 years of education. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "df = pd.read_stata('../data/QOB7080_clean.dta')\n",
    "YOB = ['YR2' + str(i) for i in range(9)]\n",
    "# Controlling for race, marital status, standrad metropolitan statistical areas, and regions of residence\n",
    "controls = ['RACE', 'MARRIED', 'SMSA',\n",
    "            'NEWENG', 'MIDATL', 'ENOCENT',\n",
    "            'WNOCENT', 'SOATL', 'ESOCENT',\n",
    "            'WSOCENT', 'MT']\n",
    "y = np.matrix(df['EDUC'] >= 12).T\n",
    "X = np.matrix(df[['AGEQ', 'AGEQSQ'] + YOB + controls])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1680, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many bugs in deep learning come from having incorrectly specified matrix/vector dimensions. It is always good to develop an understanding of what your dimensions are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 197759\n",
      "Number of testing examples: m_test = 49440\n",
      "Number of features for each observation = 22\n",
      "X_train shape: (197759, 22)\n",
      "y_train shape: (197759, 1)\n",
      "X_test shape: (49440, 22)\n",
      "y_test shape: (49440, 1)\n"
     ]
    }
   ],
   "source": [
    "m_train = X_train.shape[0]\n",
    "m_test =  X_test.shape[0]\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Number of features for each observation = \" + str(num_features))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #Control for scale of inputs\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, y_train, X_test, y_test = X_train.T, y_train.T, X_test.T, y_test.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Architecture of the learning algorithm\n",
    "\n",
    "\n",
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "The cost is then computed by summing over all training examples:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Key steps**:\n",
    "In this exercise, you will carry out the following steps: \n",
    "    - Initialize the parameters of the model\n",
    "    - Learn the parameters for the model by minimizing the cost  \n",
    "    - Use the learned parameters to make predictions (on the test set)\n",
    "    - Analyse the results and conclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the parts of our algorithm\n",
    "\n",
    "The main steps for building a Neural Network are:\n",
    "1. Define the model structure (such as number of input features) \n",
    "2. Initialize the model's parameters\n",
    "3. Loop:\n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "\n",
    "You often build 1-3 separately and integrate them into one function we call `model()`.\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "We want to first implement $sigmoid( w^T x + b) = \\frac{1}{1 + e^{-(w^T x + b)}}$ to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1/(1 + np.exp(-z))    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing parameters\n",
    "\n",
    "We will initialize w and bias to be zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias)\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward and Backward propagation\n",
    "\n",
    "Now that our parameters are initialized, we can do the \"forward\" and \"backward\" propagation steps for learning the parameters.\n",
    "\n",
    "Forward Propagation:\n",
    "- We have X\n",
    "- We compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- We calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)})$\n",
    "\n",
    "Here are the two formulas we will be using: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    dw -- gradient of the loss with respect to w, thus same shape as w\n",
    "    db -- gradient of the loss with respect to b, thus same shape as b\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    A = sigmoid(np.dot(w.T, X) + b)              # compute activation\n",
    "    cost = np.sum((np.multiply((-np.log(A)), Y) + np.multiply((-np.log(1 - A)), (1 - Y))))/m  # compute cost\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    dw = (np.dot(X,(A - Y).T))/m\n",
    "    db = (np.sum(A - Y))/m\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "- We have initialized our parameters.\n",
    "- We are also able to compute a cost function and its gradient.\n",
    "- Now, we want to update the parameters using gradient descent.\n",
    "\n",
    "The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Cost and gradient calculation (≈ 1-4 lines of code)\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        w = w - (learning_rate*dw)\n",
    "        b = b - (learning_rate*db)\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 20 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        # Print the cost every 20 training iterations\n",
    "        if print_cost and i % 20 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function will output the learned w and b. We now need to use w and b to predict the labels for a dataset X. There are two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    A = sigmoid(np.dot(w.T, X) + b)           # Dimentions = (1, m)\n",
    "    Y_prediction = (A >= 0.5)*1\n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we've implemented several functions that:\n",
    "- Initialize (w,b)\n",
    "- Optimize the loss iteratively to learn parameters (w,b):\n",
    "    - computing the cost and its gradient \n",
    "    - updating the parameters using gradient descent\n",
    "- Use the learned (w,b) to predict the labels for a given set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all functions into a model ##\n",
    "\n",
    "We will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to true to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # initialize parameters with zeros\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 62.46795341804924 %\n",
      "test accuracy: 62.44943365695793 %\n"
     ]
    }
   ],
   "source": [
    "d = model(X_train, y_train, X_test, y_test, num_iterations=500, learning_rate=0.1, print_cost=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per 20)')\n",
    "plt.title(\"Learning rate =\" + str(d[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Logistic Regression\n",
    "\n",
    "The one-layer neural network is essentially identical to a logistic regression. We can see that only 1 percent of the prediction labels are different. This subtle difference can be attributed to our choice of learning rate, and the optimization method we pick to maximize our likelihood below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.653305\n",
      "         Iterations 5\n",
      "Testing accuracy is 62.57281553398058 %\n",
      "1.1468446601941749 percent of the prediction results are different\n"
     ]
    }
   ],
   "source": [
    "X_train_with_constant = sm.add_constant(X_train.T)\n",
    "X_test_with_constant = sm.add_constant(X_test.T)\n",
    "\n",
    "logit_res = sm.Logit(y_train.T, X_train_with_constant).fit(method='newton')\n",
    "y_pred = (logit_res.predict(X_test_with_constant)>=0.5)*1.0\n",
    "print(f'Testing accuracy is {100 - np.mean(np.abs(np.matrix(y_pred) - y_test))*100} %')\n",
    "print(f'{np.mean(np.abs(np.matrix(y_pred) - d[\"Y_prediction_test\"])) * 100} percent of the prediction results are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks for Different Tasks\n",
    "\n",
    "Now, I will demonstrate how to use neural network for two types of tasks: discrete prediction and continuous prediction. For classification tasks, we can use `MLPClassifier.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6269449178039938\n",
      "0.6287419093851133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc679834070>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLP_class = MLPClassifier(hidden_layer_sizes=(4, 2), random_state=1680,\n",
    "                          max_iter=200, learning_rate_init=0.0001)\n",
    "MLP_class.fit(X_train.T, np.ravel(y_train)) #estimate params\n",
    "print(accuracy_score(y_train.T, MLP_class.predict(X_train.T))) # within sample accuracy\n",
    "print(accuracy_score(y_test.T, MLP_class.predict(X_test.T))) # out of sample accuracy\n",
    "plt.plot(MLP_class.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regressions, we can use `MLPRegressor`, which minimizes squared error. We can use it for the prediction of log weekly wage. We first load in our X and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.matrix(df['LWKLYWGE']).T\n",
    "X = np.matrix(df[['EDUC', 'AGEQ', 'AGEQSQ'] + YOB + controls])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1680)\n",
    "scaler = StandardScaler() #Control for scale of inputs\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc679494af0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLP_reg = MLPRegressor(hidden_layer_sizes=(4, 2), random_state=1680,\n",
    "                       max_iter=200, learning_rate_init=0.0001)\n",
    "MLP_reg.fit(X_train, np.ravel(y_train)) #estimate params\n",
    "plt.plot(MLP_reg.loss_curve_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more customizability, check out tensorflow. To tune hyperparameters, we can set up grids of hyperparameters. Some of the things we usually tune for are learning rates, batch sizes, solver, and network sizes. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 213.4,
   "position": {
    "height": "235.4px",
    "left": "1160px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
